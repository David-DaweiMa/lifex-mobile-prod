name: Scrape Events (Rendered)

on:
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run (no DB writes)'
        type: boolean
        default: true
      sample_limit:
        description: 'Detail sample size in dry-run'
        type: number
        default: 10
      concurrency:
        description: 'Detail extraction concurrency'
        type: number
        default: 3
      max_retries:
        description: 'Max retries for detail extraction'
        type: number
        default: 2
  schedule:
    - cron: '25 3 * * *'

concurrency:
  group: scrape-events-rendered
  cancel-in-progress: false

jobs:
  scrape-rendered-events:
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      DRY_RUN: 'true'
      SAMPLE_LIMIT: '10'
      CONCURRENCY: '3'
      MAX_RETRIES: '2'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Disable DRY_RUN on schedule
        if: github.event_name == 'schedule'
        run: echo "DRY_RUN=false" >> $GITHUB_ENV

      - name: Apply manual inputs
        if: github.event_name == 'workflow_dispatch'
        run: |
          echo "DRY_RUN=${{ inputs.dry_run }}" >> $GITHUB_ENV
          echo "SAMPLE_LIMIT=${{ inputs.sample_limit }}" >> $GITHUB_ENV
          echo "CONCURRENCY=${{ inputs.concurrency }}" >> $GITHUB_ENV
          echo "MAX_RETRIES=${{ inputs.max_retries }}" >> $GITHUB_ENV

      - name: Install Playwright (local)
        run: |
          npm init -y
          npm i playwright@1
          npx playwright install --with-deps chromium

      - name: Render and extract events (seeds), then upsert to Supabase (dry-run by default)
        shell: bash
        run: |
          npm i playwright@1
          node - <<'NODE'
          const { chromium } = require('playwright');

          const SUPABASE_URL = process.env.SUPABASE_URL;
          const SUPABASE_SERVICE_ROLE_KEY = process.env.SUPABASE_SERVICE_ROLE_KEY;
          const DRY_RUN = String(process.env.DRY_RUN || 'true').toLowerCase() === 'true';
          const SAMPLE_LIMIT = parseInt(process.env.SAMPLE_LIMIT || '10', 10);
          const CONCURRENCY = Math.max(1, parseInt(process.env.CONCURRENCY || '3', 10));
          const MAX_RETRIES = Math.max(0, parseInt(process.env.MAX_RETRIES || '2', 10));
          const sleep = (ms) => new Promise(res => setTimeout(res, ms));

          async function withRetries(fn, maxRetries, baseDelayMs = 1000) {
            let attempt = 0;
            while (true) {
              try {
                return await fn();
              } catch (e) {
                if (attempt >= maxRetries) throw e;
                const delay = baseDelayMs * Math.pow(2, attempt); // backoff
                await sleep(delay);
                attempt++;
              }
            }
          }

          async function runWithConcurrency(tasks, concurrency) {
            const results = new Array(tasks.length);
            let next = 0;
            async function worker() {
              while (true) {
                const i = next++;
                if (i >= tasks.length) break;
                results[i] = await tasks[i]();
              }
            }
            const workers = Array.from({ length: concurrency }, () => worker());
            await Promise.all(workers);
            return results;
          }

          function htmlDecode(str) {
            if (!str) return str;
            return String(str)
              .replace(/&amp;/gi, '&')
              .replace(/&#x2B;/gi, '+')
              .replace(/&plus;/gi, '+')
              .replace(/&lt;/gi, '<')
              .replace(/&gt;/gi, '>')
              .replace(/&quot;/gi, '"')
              .replace(/&#39;/gi, "'");
          }

          function normalizeDateTime(input) {
            if (!input) return null;
            let s = htmlDecode(String(input).trim());
            // Replace space between date and time with 'T' if present
            if (/^\d{4}-\d{2}-\d{2} \d{2}:\d{2}/.test(s)) {
              s = s.replace(' ', 'T');
            }
            // Trim fractional seconds to max 6 digits to satisfy Postgres
            s = s.replace(/\.(\d{6})\d+([Z\+\-])/, '.$1$2');
            const d = new Date(s);
            if (!Number.isNaN(d.valueOf())) return d.toISOString();
            // Retry: remove any remaining HTML entities and try again
            s = s.replace(/&#[xX]([0-9A-Fa-f]+);/g, (_, hex) => String.fromCharCode(parseInt(hex, 16)));
            const d2 = new Date(s);
            return Number.isNaN(d2.valueOf()) ? null : d2.toISOString();
          }


          if (!SUPABASE_URL || !SUPABASE_SERVICE_ROLE_KEY) {
            throw new Error('Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY');
          }

          const sources = [
            'https://ourauckland.aucklandcouncil.govt.nz/events/',
            'https://www.aucklandlive.co.nz/whats-on',
            'https://www.aucklandmuseum.com/visit/whats-on',
            'https://www.aucklandartgallery.com/whats-on',
            'https://www.aucklandlibraries.govt.nz/pages/events.aspx'
          ];

          const pathHints = [
            '/events', '/whats-on', '/visit/whats-on', '/whatson', '/show', '/shows'
          ];

          function absolutize(href, base) {
            try { return new URL(href, base).toString(); } catch { return href; }
          }

          function looksLikeEventUrl(u) {
            try {
              const { pathname } = new URL(u);
              const p = pathname.toLowerCase();
              return pathHints.some(h => p.includes(h));
            } catch { return false; }
          }

          (async () => {
            const browser = await chromium.launch({ headless: true });
            const context = await browser.newContext({ userAgent: 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome Safari' });

            const all = [];
            for (const url of sources) {
              const page = await context.newPage();
              try {
                await page.goto(url, { waitUntil: 'networkidle', timeout: 60000 });
                const base = url;

                const items = await page.$$eval('a[href]', as => as.map(a => ({
                  href: a.getAttribute('href'),
                  text: (a.textContent || '').trim(),
                })));

                const uniq = new Map();
                for (const it of items) {
                  if (!it.href) continue;
                  const abs = absolutize(it.href, base);
                  if (!looksLikeEventUrl(abs)) continue;
                  if (!uniq.has(abs)) uniq.set(abs, it.text || abs);
                }

                for (const [absUrl, title] of uniq.entries()) {
                  all.push({
                    source: `render:${new URL(base).host}`,
                    external_id: absUrl,
                    title: title || undefined,
                    description: null,
                    starts_at: null,
                    ends_at: null,
                    timezone: 'Pacific/Auckland',
                    venue_name: null,
                    city: null,
                    url: absUrl,
                    raw: { from: base }
                  });
                  if (all.length >= 400) break;
                }
              } catch (e) {
                console.log('Render error:', url, String(e));
              } finally {
                await page.close();
              }
              if (all.length >= 400) break;
            }

            console.log('Collected items (seed URLs):', all.length);

            // Detail extraction: visit each seed URL and try to extract structured info
            async function extractDetails(page, detailUrl) {
              try {
                await page.goto(detailUrl, { waitUntil: 'networkidle', timeout: 60000 });
              } catch (e) {
                return null;
              }

              const data = await page.evaluate(() => {
                const result = { title: null, description: null, starts_at: null, ends_at: null, venue_name: null, city: null };

                // JSON-LD Event
                const scripts = Array.from(document.querySelectorAll('script[type="application/ld+json"]'));
                let foundEvent = null;
                for (const s of scripts) {
                  let jsonText = s.textContent || '';
                  try {
                    const parsed = JSON.parse(jsonText.trim());
                    const nodes = Array.isArray(parsed) ? parsed : [parsed];
                    for (const node of nodes) {
                      const types = Array.isArray(node['@type']) ? node['@type'] : [node['@type']];
                      if (types && types.some(t => String(t).toLowerCase() === 'event')) {
                        foundEvent = node;
                        break;
                      }
                      if (node['@graph']) {
                        const gnodes = Array.isArray(node['@graph']) ? node['@graph'] : [node['@graph']];
                        for (const g of gnodes) {
                          const gtypes = Array.isArray(g['@type']) ? g['@type'] : [g['@type']];
                          if (gtypes && gtypes.some(t => String(t).toLowerCase() === 'event')) {
                            foundEvent = g;
                            break;
                          }
                        }
                      }
                    }
                    if (foundEvent) break;
                  } catch {}
                }

                if (foundEvent) {
                  result.title = foundEvent.name || null;
                  result.description = foundEvent.description || null;
                  result.starts_at = foundEvent.startDate || null;
                  result.ends_at = foundEvent.endDate || null;
                  const loc = foundEvent.location;
                  if (loc) {
                    const first = Array.isArray(loc) ? loc[0] : loc;
                    result.venue_name = first && (first.name || null);
                    const addr = first && first.address;
                    if (addr) {
                      if (typeof addr === 'string') {
                        result.city = null;
                      } else {
                        result.city = addr.addressLocality || addr.addressRegion || null;
                      }
                    }
                  }
                }

                // Fallbacks
                if (!result.title) {
                  const ogt = document.querySelector('meta[property="og:title"]');
                  result.title = (ogt && ogt.getAttribute('content')) || document.title || null;
                }
                if (!result.description) {
                  const ogd = document.querySelector('meta[property="og:description"]');
                  const md = document.querySelector('meta[name="description"]');
                  result.description = (ogd && ogd.getAttribute('content')) || (md && md.getAttribute('content')) || null;
                }

                return result;
              });

              return data;
            }

            // If dry run, skip detail extraction DB writes but still probe a few for visibility
            const sampleLimit = DRY_RUN ? Math.min(all.length, Number.isFinite(SAMPLE_LIMIT) ? SAMPLE_LIMIT : 10) : all.length;
            const tasks = [];
            for (let i = 0; i < sampleLimit; i++) {
              const item = all[i];
              tasks.push(async () => {
                const runner = async () => {
                  const page = await context.newPage();
                  try {
                    const detail = await extractDetails(page, item.url);
                    if (!detail) return null;
                    const normStart = normalizeDateTime(detail.starts_at);
                    const normEnd = normalizeDateTime(detail.ends_at);
                    return {
                      ...item,
                      title: detail.title || item.title,
                      description: detail.description,
                      starts_at: normStart,
                      ends_at: normEnd,
                      venue_name: detail.venue_name,
                      city: detail.city,
                    };
                  } finally {
                    await page.close();
                  }
                };
                return await withRetries(runner, MAX_RETRIES, 800);
              });
            }
            const detailResults = await runWithConcurrency(tasks, CONCURRENCY);
            const detailItems = detailResults.filter(Boolean);

            console.log('Detail-enriched items:', detailItems.length, 'of', all.length);
            if (DRY_RUN || detailItems.length === 0) {
              await browser.close();
              console.log(JSON.stringify({ ok: true, dryRun: true, collected: all.length, detailedSample: detailItems.length }));
              return;
            }

            const rpcUrl = `${SUPABASE_URL}/rest/v1/rpc/admin_upsert_event_scrape_cache_batch`;
            const resp = await fetch(rpcUrl, {
              method: 'POST',
              headers: {
                'apikey': SUPABASE_SERVICE_ROLE_KEY,
                'Authorization': `Bearer ${SUPABASE_SERVICE_ROLE_KEY}`,
                'Content-Type': 'application/json'
              },
              body: JSON.stringify({ p_items: detailItems })
            });
            if (!resp.ok) {
              const t = await resp.text();
              throw new Error(`RPC upsert failed ${resp.status}: ${t}`);
            }
            await browser.close();
            console.log(JSON.stringify({ ok: true, dryRun: false, upserted: detailItems.length }));
          })().catch(err => {
            console.error('Job failed:', err);
            process.exit(1);
          });
          NODE

      - name: Hints
        run: |
          echo "Set repository secrets SUPABASE_URL and SUPABASE_SERVICE_ROLE_KEY before enabling schedule."

